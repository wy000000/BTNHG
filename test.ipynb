{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0290540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BTNHGV2ParameterClass import BTNHGV2ParameterClass\n",
    "import os\n",
    "import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "import numpy as np\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "import psutil\n",
    "import sys\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    cohen_kappa_score,\n",
    "    matthews_corrcoef,\n",
    "\tconfusion_matrix,\n",
    "\tConfusionMatrixDisplay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb81da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Windows\n",
      "Architecture: X86_64\n",
      "CPU: Intel(R) Core(TM) i7-6700HQ CPU @ 2.60GHz\n",
      "Cores: 4\n",
      "memory_total_GB: 15.89\n",
      "gpu_available: True\n",
      "gpu_count: 1\n",
      "GPU 0: NVIDIA GeForce GTX 1060 6.0 GB\n",
      "python_version: 3.13.9\n",
      "torch_version: 2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import cpuinfo\n",
    "info = {}\n",
    "\n",
    "# üñ•Ô∏è Á°¨‰ª∂‰ø°ÊÅØ\n",
    "info[\"System\"] = platform.system()\n",
    "info[\"Architecture\"] = cpuinfo.get_cpu_info()['arch']\n",
    "info[\"CPU\"] = cpuinfo.get_cpu_info()['brand_raw']\n",
    "info[\"Cores\"] = psutil.cpu_count(logical=False)\n",
    "info[\"memory_total_GB\"] = round(psutil.virtual_memory().total / (1024**3), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# GPU ‰ø°ÊÅØÔºàPyTorchÔºâ\n",
    "if torch.cuda.is_available():\n",
    "\tinfo[\"gpu_available\"] = True\n",
    "\tinfo[\"gpu_count\"] = torch.cuda.device_count()\n",
    "\n",
    "\tfor i in range(info[\"gpu_count\"]):\n",
    "\t\tprops = torch.cuda.get_device_properties(i)\n",
    "\t\tname = torch.cuda.get_device_name(i)\n",
    "\t\ttotal_mem = round(props.total_memory / (1024**3), 2)  # ËΩ¨Êç¢‰∏∫ GB\n",
    "\t\tinfo[f\"GPU {i}\"] = f\"{name} {total_mem} GB\"\n",
    "else:\n",
    "\tinfo[\"gpu_available\"] = False\n",
    "\n",
    "# üì¶ ËΩØ‰ª∂‰ø°ÊÅØ\n",
    "info[\"python_version\"] = sys.version.split()[0]\n",
    "info[\"torch_version\"] = torch.__version__\n",
    "# try:\n",
    "# \timport tensorflow as tf\n",
    "# \tinfo[\"tensorflow_version\"] = tf.__version__\n",
    "# except ImportError:\n",
    "# \tinfo[\"tensorflow_version\"] = None\n",
    "#ÈÄêË°åÊâìÂç∞info\n",
    "for key, value in info.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
